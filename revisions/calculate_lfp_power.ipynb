{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb2abf4",
   "metadata": {},
   "source": [
    "### Calculate power in set frequency bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b51b02a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "from spikeinterface.extractors.neoextractors import SpikeGLXRecordingExtractor\n",
    "from spectral_connectivity import Multitaper, Connectivity\n",
    "from phylib.io.model import load_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee8d8aa",
   "metadata": {},
   "source": [
    "### Import functions & classes from Yggdrasil library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db997a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_depths(data_dir):\n",
    "    '''Returns dictionary of depths of best channel for each cluster\n",
    "\n",
    "    Parameters:\n",
    "        data_dir:    path to sorted spikes directory\n",
    "    Returns:\n",
    "        depths:      dictionary, cluster ID -> best channel depth\n",
    "    '''\n",
    "    # load the cluster info\n",
    "    ch_pos = np.load(join(data_dir,'channel_positions.npy'))\n",
    "    group = pd.read_table(join(data_dir,'cluster_group.tsv'))\n",
    "    templates = np.load(join(data_dir,'templates.npy'))\n",
    "    n_templates = len(templates)\n",
    "\n",
    "    # find the good & MUA clusters\n",
    "    good_clusters = group['cluster_id'][group['group']== 'good']\n",
    "\n",
    "    # load TemplateModel instance\n",
    "    model = load_model(join(data_dir,'params.py'))\n",
    "\n",
    "    # get y coords of units\n",
    "    depths = np.zeros(shape=(len(good_clusters),1))\n",
    "    g = 0\n",
    "    for index, value in good_clusters.items():\n",
    "        if value<n_templates: #hacky solution for clusters going beyond templates\n",
    "            cluster = model.get_template(value)\n",
    "            depths[g] = ch_pos[cluster.best_channel][1]\n",
    "            g = g+1\n",
    "    \n",
    "    return depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eabdf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ephys_vs_atlas(data_dir, lfp_file):\n",
    "    '''Plots & saves theta power & # clusters vs channels\n",
    "\n",
    "    Parameters:\n",
    "        data_dir:       path to sorted spikes directory\n",
    "        lfp_file:       path to lf.bin\n",
    "    '''\n",
    "    # extract traces & sampling rate\n",
    "    lfp_data = SpikeGLXRecordingExtractor(lfp_file, stream_id='imec0.lf')\n",
    "    samp_rate = lfp_data.get_sampling_frequency()\n",
    "\n",
    "    # get a subset of the data for visualization\n",
    "    # this takes a 10s chunk 10min into recording, but you can change this (it shouldn't change much)\n",
    "    sample = lfp_data.get_traces(start_frame=1500000, end_frame=1525000)\n",
    "\n",
    "    # calculate spectrogram\n",
    "    window = 0.50  # seconds\n",
    "    m = Multitaper(sample, sampling_frequency=samp_rate,\n",
    "                   time_window_duration=window, time_window_step=window)\n",
    "    c = Connectivity.from_multitaper(m)  # shape: windows x freqs x channels\n",
    "\n",
    "    # get power in theta band\n",
    "    freqs = (6, 12)\n",
    "    band_start = np.argmin(np.abs(c.frequencies - freqs[0]))\n",
    "    band_end = np.argmin(np.abs(c.frequencies - freqs[1]))\n",
    "    power = np.mean(np.mean(c.power()[:, band_start:band_end, :].squeeze(), 1), 0)\n",
    "\n",
    "    # get spike cluster depths\n",
    "    depths = get_cluster_depths(data_dir)\n",
    "    hist, bin_edges = np.histogram(depths, bins=np.arange(0., 3860., 20.))\n",
    "    bin_edges = bin_edges[0:-1]/10\n",
    "\n",
    "    # plot theta power for each channel & number of clusters at each depth\n",
    "    # with overlay of atlas registration\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    ax.plot(np.log(power), c='black', label='Theta')\n",
    "    ax.plot(bin_edges, hist, c='grey', label='Clusters')\n",
    "    fig.legend(loc='upper right')\n",
    "    y_limits = ax.get_ylim()\n",
    "    y_limit = y_limits[1] - (y_limits[1]-y_limits[0])/5\n",
    "    ax.set(xlabel='Channel', ylabel='Log(Power) OR # Clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4626e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "from os.path import exists\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from spikeinterface.extractors.neoextractors import SpikeGLXRecordingExtractor\n",
    "from spectral_connectivity import Multitaper, Connectivity\n",
    "from scipy.signal import filtfilt, remez\n",
    "\n",
    "\n",
    "class LFP:\n",
    "\n",
    "    '''LFP and related functions from a single session\n",
    "\n",
    "    Attributes:\n",
    "        name (string):               path to LFP file\n",
    "        rec_file_path (string):      path to spikeGLX folder containing lf.bin\n",
    "        lfp (ts x channels float):   array of LFP voltage values\n",
    "        timestamps (1xts float):     array of timestamps\n",
    "        start (int):                 start time (s)\n",
    "        end (int):                   end time (s)\n",
    "        rate (int):                  samples/s of downsampled stream\n",
    "        n_chan (int):                # channels\n",
    "        downsample_factor (int):     downsample factor\n",
    "        max_theta_channel (int):     index of channel with highest theta power\n",
    "                                        within user-specified channel subset & time subset\n",
    "\n",
    "    Methods:\n",
    "        load\n",
    "        save\n",
    "        subset_by_channel\n",
    "        subset_by_time\n",
    "        calc_max_theta_channel\n",
    "\n",
    "    Functions:\n",
    "        get_inclusive_indices\n",
    "        multitaper_filtered_power\n",
    "        plot_spectrogram\n",
    "        plot_psd\n",
    "        design_filter\n",
    "        bandpass_filter\n",
    "        hilbert_envelope_phase_freq\n",
    "        get_cycle_intervals\n",
    "    '''\n",
    "\n",
    "    def __init__(self, name=\"\", rec_file_path=\"\", start=None, end=None, n_chan=384, \n",
    "                 probe_type=1, downsample_factor=4, channels=None):\n",
    "        '''Loads or builds spiketimes and relevant variables\n",
    "\n",
    "        Parameters:\n",
    "            name (string):              optional, path to LFP file\n",
    "            rec_file_path (string):     optional, path to spikeGLX folder with lf.bin\n",
    "            start (int):                optional, start time (sec)\n",
    "            end (int):                  optional, end time (sec)\n",
    "            n_chan (int):               optional, # channels\n",
    "            probe_type (int):           optional, NPX probe type (1 or 2)\n",
    "            downsample_factor (int):    optional, downsample factor\n",
    "            channels (list of ints):    optional, indices of channels to include\n",
    "        '''\n",
    "\n",
    "        self.name = name\n",
    "\n",
    "        # if instance already defined\n",
    "        if exists(self.name):\n",
    "            self.load()\n",
    "        else:\n",
    "            self.rec_file_path = rec_file_path\n",
    "            self.start = start\n",
    "            self.end = end\n",
    "            self.n_chan = n_chan\n",
    "            self.downsample_factor = downsample_factor\n",
    "            self.rate = 2500\n",
    "\n",
    "            # design filter\n",
    "            hardware_filter = signal.butter(\n",
    "                1, Wn=[0.5, 500], btype='band', fs=self.rate)\n",
    "            # preprocess_filter = signal.butter(12, Wn=[1,500], btype='band', fs=self.rate) #catGT specs\n",
    "            preprocess_filter = signal.butter(\n",
    "                2, Wn=[0.1, 300], btype='band', fs=self.rate)  # Frank lab specs\n",
    "\n",
    "            lfp_extractor = SpikeGLXRecordingExtractor(self.rec_file_path, \\\n",
    "                                                       stream_id='imec0.lf')\n",
    "            \n",
    "            if self.start is None:\n",
    "                self.start = 0\n",
    "            if self.end is None:\n",
    "                ap_meta_file = glob.glob(join(ephys_path,'*.imec0.ap.meta'))\n",
    "                file_stream = open(ap_meta_file[0])\n",
    "                for line in file_stream:\n",
    "                    if 'fileTimeSecs' in line:\n",
    "                        self.end = float(re.findall(r'(\\d+\\.\\d+)', line)[0])\n",
    "            \n",
    "            # ts x channels empty ndarray\n",
    "            n_samp = int((self.end*self.rate-self.start * \\\n",
    "                         self.rate)/self.downsample_factor)+1\n",
    "            self.lfp = np.empty((n_samp, self.n_chan))\n",
    "            \n",
    "            if channels is None:\n",
    "                channels = list(range(n_chan))\n",
    "\n",
    "            for i, c in enumerate(channels):\n",
    "                # subsetted by channel to reduce RAM requirements\n",
    "                lfp_c = lfp_extractor.get_traces(channel_ids=[f\"imec0.lf#LF{c}\"],\n",
    "                                                start_frame=int(self.start*self.rate),\n",
    "                                                end_frame=int(self.end*self.rate))\n",
    "                lfp_c = lfp_c.T\n",
    "\n",
    "                if probe_type==1:\n",
    "                    # correct for analog filter phase shift\n",
    "                    # reverse, filter in 1 direction, and reverse again\n",
    "                    lfp_c = np.flip(signal.lfilter(*hardware_filter, np.flip(lfp_c)))\n",
    "    \n",
    "                    # initial filtering (similar to what catGT would have done)\n",
    "                    lfp_c = signal.filtfilt(*preprocess_filter, lfp_c)\n",
    "\n",
    "                # downsample to reduce filesize\n",
    "                downsampled_lfp = signal.decimate(\n",
    "                    lfp_c, self.downsample_factor)\n",
    "                # the sglx recording extractor sometimes cuts off the last few LFP datapoints\n",
    "                # so leaves those blank in the LFP array\n",
    "                self.lfp[0:len(downsampled_lfp[0]), i] = downsampled_lfp\n",
    "\n",
    "            # store timestamps for future temporal filtering\n",
    "            self.rate = self.rate/self.downsample_factor  # new downsampled rate\n",
    "            self.timestamps = np.arange(0, self.end-self.start, 1/self.rate)\n",
    "\n",
    "    def load(self):\n",
    "        '''Load file'''\n",
    "        # load metadata as text file, data as csv\n",
    "        name = self.name\n",
    "        meta_name = self.name[:-4]+'_metadata.txt'\n",
    "        file = open(meta_name, 'r')\n",
    "        self.__dict__ = eval(file.read())\n",
    "        self.name = name\n",
    "\n",
    "        with open(self.name, \"r\") as file:\n",
    "            lfp_df = pd.read_csv(file)\n",
    "        self.timestamps = np.array(lfp_df['Timestamps'])\n",
    "        self.lfp = np.array(lfp_df)\n",
    "        self.lfp = self.lfp[:, 1:]  # remove Timestamps column\n",
    "\n",
    "    def save(self):\n",
    "        '''Save to file'''\n",
    "        # save metadata as text file, data as csv\n",
    "        lfp = deepcopy(self.lfp)\n",
    "        del self.lfp\n",
    "        timestamps = deepcopy(self.timestamps)\n",
    "        del self.timestamps\n",
    "\n",
    "        meta_name = self.name[:-4]+'_metadata.txt'\n",
    "        with open(meta_name, 'w') as file:\n",
    "            file.write(str(self.__dict__))\n",
    "\n",
    "        ts_df = pd.DataFrame(data=timestamps, columns=['Timestamps'])\n",
    "        lfp_df = pd.DataFrame(data=lfp)\n",
    "        lfp_df = pd.concat([ts_df, lfp_df], axis=1)\n",
    "        lfp_df.to_csv(self.name, index=False)\n",
    "\n",
    "        self.lfp = lfp\n",
    "        self.timestamps = timestamps\n",
    "\n",
    "    # %% Subsetting functions\n",
    "    def subset_by_channel(self, subset_channels):\n",
    "        '''Subset lfp on specific channels, eg after running electrodes.subset_by_location()'''\n",
    "        self.lfp = self.lfp[:, subset_channels]\n",
    "        self.n_chan = len(subset_channels)\n",
    "\n",
    "    def subset_by_time(self, intervals):\n",
    "        '''Subset lfp within windows, e.g. during epochs or running'''\n",
    "        if intervals.ndim == 1:  # if just 1 interval\n",
    "            # convert vector to 2D array with 1 row\n",
    "            intervals = intervals[np.newaxis]\n",
    "\n",
    "        # append all timestamps within the windows (inclusive)\n",
    "        subset_timestamps = np.empty(0)\n",
    "        subset_indices = np.empty(0)\n",
    "        for i in intervals:\n",
    "            subset_timestamps = np.append(subset_timestamps,\n",
    "                                          self.timestamps[(self.timestamps >= i[0])\n",
    "                                                          & (self.timestamps <= i[1])])\n",
    "            subset_indices = np.append(subset_indices,\n",
    "                                       np.asarray(np.where((self.timestamps >= i[0])\n",
    "                                                           & (self.timestamps <= i[1]))))\n",
    "\n",
    "        # append all lfp samples within the windows (inclusive)\n",
    "        subset_indices = subset_indices.astype(int)\n",
    "        subset_lfp = self.lfp[subset_indices, :]\n",
    "\n",
    "        self.lfp = subset_lfp\n",
    "        self.timestamps = subset_timestamps\n",
    "\n",
    "    # %% Calculating features\n",
    "    def calc_max_theta_channel(self, channels, interval):\n",
    "        '''Calculate & store the channel with the highest theta power'''\n",
    "        lfp_theta = deepcopy(self)\n",
    "        lfp_theta.subset_by_time(interval)\n",
    "        lfp_theta.subset_by_channel(channels)\n",
    "        power = multitaper_filtered_power(\n",
    "            lfp_theta.lfp, low=THETA[0], high=THETA[1])\n",
    "        self.max_theta_channel = channels[np.argmax(power)]\n",
    "\n",
    "\n",
    "# %% Filter parameters\n",
    "# freq band = [low, high, bandpass]\n",
    "THETA = [5, 11, 1]\n",
    "SLOW_WAVE = [1, 4, 0.5]\n",
    "SPINDLE = [12, 18, 1]\n",
    "SHARP_WAVE = [0, 30, 5]\n",
    "SLOW_GAMMA = [20, 50, 5]\n",
    "FAST_GAMMA = [50, 110, 5]\n",
    "RIPPLE = [125, 200, 5]\n",
    "\n",
    "# %% External functions\n",
    "\n",
    "\n",
    "def get_inclusive_indices(low, high, freqs):\n",
    "    '''Find the indices of the target band (inclusive)\n",
    "    Can also use np.argmin(np.abs(c.frequencies - freqs[0]))\n",
    "    But this method ensures freqs[low_idx]<=low and freqs[high_idx]>=high'''\n",
    "    low_idx = 0\n",
    "    high_idx = len(freqs)-1\n",
    "    for i, freq in enumerate(freqs):\n",
    "        if (freq > low) and (freqs[i-1] <= low):\n",
    "            low_idx = i-1\n",
    "        if (freq >= high) and (freqs[i-1] < high):\n",
    "            high_idx = i\n",
    "            break\n",
    "    return low_idx, high_idx\n",
    "\n",
    "\n",
    "def multitaper_filtered_power(lfp, rate=625, low=1, high=300, window=0.5):\n",
    "    '''Use multi-taper spectrogram to calculate power in freq. window'''\n",
    "    # calculate spectrogram\n",
    "    m = Multitaper(lfp, sampling_frequency=rate,\n",
    "                   time_window_duration=window, time_window_step=window)\n",
    "    c = Connectivity.from_multitaper(m)  # shape: windows x freqs x channels\n",
    "\n",
    "    # get power in freq band\n",
    "    band_start, band_end = get_inclusive_indices(low, high, c.frequencies)\n",
    "    power = np.mean(c.power()[:, band_start:band_end, :].squeeze(), 1)\n",
    "    total_power = np.mean(power, 0)\n",
    "    return power, total_power\n",
    "\n",
    "\n",
    "def plot_spectrogram(lfp, rate=625, low=1, high=300, low_display=1,\n",
    "                     high_display=300, window=0.5):\n",
    "    '''Use multi-taper spectrogram to plot power across all freqs in window on a single channel'''\n",
    "    # calculate spectrogram\n",
    "    m = Multitaper(lfp, sampling_frequency=rate,\n",
    "                   time_window_duration=window, time_window_step=window)\n",
    "    c = Connectivity.from_multitaper(m)  # shape: windows x freqs x channels\n",
    "\n",
    "    # find the target bands (inclusive)\n",
    "    low_idx, high_idx = get_inclusive_indices(low, high, c.frequencies)\n",
    "    low_disp_idx, high_disp_idx = get_inclusive_indices(\n",
    "        low_display, high_display, c.frequencies)\n",
    "\n",
    "    # extract power and timestamps\n",
    "    power = np.mean(c.power()[:, low_idx:high_idx, 0].squeeze(), 1)\n",
    "    n_samples = int(window * rate)\n",
    "    timestamps = np.arange(0, lfp.shape[0])\n",
    "    index = timestamps[np.arange(1, power.shape[0] * n_samples + 1, n_samples)]\n",
    "    power = pd.DataFrame(power, index=index)\n",
    "    timestamps = power.index/rate\n",
    "\n",
    "    # plot spectrogram\n",
    "    f, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.pcolormesh(timestamps, c.frequencies[low_disp_idx:high_disp_idx],\n",
    "                  c.power()[:, low_disp_idx:high_disp_idx, 0].squeeze().T, cmap='viridis')\n",
    "    ax.set(xlabel='Time (s)', ylabel='Frequency (Hz)')\n",
    "\n",
    "    # plot theta power over time\n",
    "    f, ax = plt.subplots(figsize=(10, 3))\n",
    "    ax.plot(timestamps, power.values)\n",
    "    ax.set(xlabel='Time (s)', ylabel='Theta Power (uV)',\n",
    "           xlim=[timestamps[0], timestamps[-1]])\n",
    "\n",
    "\n",
    "def plot_psd(lfp, rate=625):\n",
    "    '''Plots PSD for a single channel'''\n",
    "    freqs, psd = signal.welch(np.squeeze(lfp), rate)\n",
    "    plt.semilogy(freqs, psd)\n",
    "    plt.xlim([0, 100])\n",
    "    plt.ylim([0.1, 1000])\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('PSD (V**2/Hz)')\n",
    "    plt.show()\n",
    "\n",
    "# following 2 functions adapted from\n",
    "# https://github.com/Eden-Kramer-Lab/ripple_detection/blob/master/ripple_detection/core.py\n",
    "\n",
    "\n",
    "def design_filter(rate=625, low=1, high=300, pass_band=1):\n",
    "    '''Returns a remez (aka equiripple) bandpass filter\n",
    "    Parameters\n",
    "    ----------\n",
    "    samp_rate : sampling frequency (Hz)\n",
    "    freqs : tuple of low & high freqs (Hz)\n",
    "    pass_band : width of pass band (Hz)\n",
    "    Returns\n",
    "    -------\n",
    "    filtered_data : array_like, shape (n_time,)\n",
    "    '''\n",
    "    order = 101\n",
    "    nyquist = 0.5*rate\n",
    "    desired = [0, low - pass_band, low,\n",
    "               high, high + pass_band, nyquist]\n",
    "    return remez(order, desired, [0, 1, 0], Hz=rate), 1.0\n",
    "\n",
    "\n",
    "def bandpass_filter(lfp, rate=625, low=1, high=300, pass_band=1):\n",
    "    '''Returns a bandpass filtered signal\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array_like, shape (n_time,)\n",
    "    samp_rate : sampling frequency (Hz)\n",
    "    freqs : tuple of low & high freqs (Hz)\n",
    "    pass_band : width of pass band (Hz)\n",
    "    Returns\n",
    "    -------\n",
    "    filtered_data : array_like, shape (n_time,)\n",
    "    '''\n",
    "    filt_num, filt_denom = design_filter(rate, low, high, pass_band)\n",
    "    is_nan = np.isnan(lfp)\n",
    "    filtered_data = np.full_like(lfp, np.nan)\n",
    "    filtered_data[~is_nan] = filtfilt(\n",
    "        filt_num, filt_denom, lfp[~is_nan], axis=0)\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def hilbert_envelope_phase_freq(lfp, win=15, rate=625):\n",
    "    '''Hilbert transform to get envelope, phase, and frequency of LFP'''\n",
    "    # smooth filtered signal\n",
    "    filter_coef = signal.get_window('hann', win, fftbins=False)\n",
    "    filter_coef /= filter_coef.sum()\n",
    "    # filtfilt is expecting (channel x timestamps) shape\n",
    "    smoothed_lfp = signal.filtfilt(filter_coef, 1, lfp.T)\n",
    "    # multiple by -1 so cycle is peak-to-peak instead of trough-to-trough\n",
    "    smoothed_lfp = smoothed_lfp.T*-1 \n",
    "    \n",
    "    # hilbert transform\n",
    "    analytic_signal = signal.hilbert(smoothed_lfp, axis=0)\n",
    "    envelope = np.abs(analytic_signal)\n",
    "    inst_phase = np.unwrap(np.angle(analytic_signal))\n",
    "    inst_freq = (np.diff(inst_phase, axis=0)/(2.0*np.pi)*rate)\n",
    "    return envelope, inst_phase, inst_freq\n",
    "\n",
    "\n",
    "def get_cycle_intervals(lfp, timestamps, win=15, rate=625):\n",
    "    '''Given a (theta-filtered) 1-channel LFP trace, returns a (i,2) nparray of i intervals\n",
    "    where [intervals[i,0], intervals[i,1]] spans a single (theta) cycle\n",
    "    '''\n",
    "    _, phase, _ = hilbert_envelope_phase_freq(lfp, win, rate)\n",
    "    new_cycle = np.diff(phase, axis=0) < 0\n",
    "    new_cycle = np.append(new_cycle, [False])  # match length to timestamps\n",
    "    curr_start = timestamps[0]\n",
    "    intervals = []\n",
    "    start_indices = [0]\n",
    "    for t, time in enumerate(timestamps):\n",
    "        # when phase shifts from high (~2pi) to low (~0), start a new cycle\n",
    "        if new_cycle[t]:\n",
    "            intervals.append([curr_start, timestamps[t-1]])\n",
    "            start_indices.append(t-1)\n",
    "            curr_start = timestamps[t-1]\n",
    "        # end of the array without hitting an interval-ending new cycle\n",
    "        elif t == len(timestamps)-1:\n",
    "            intervals.append([curr_start, timestamps[t]])\n",
    "            start_indices.append(t)\n",
    "\n",
    "    start_indices = start_indices[:-1]  # remove end index\n",
    "    return intervals, start_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45b78a6",
   "metadata": {},
   "source": [
    "### Read session list and calculate power in each frequency band over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d9e628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = pd.read_csv(r'\\\\oak-smb-giocomo.stanford.edu\\groups\\giocomo\\fkmasuda\\fkm_analysis\\EAJ_revisions\\wt_ket_sessions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54cc6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot locations of cells and theta power along electrode shank to select sample channel\n",
    "ephys_base_dir = r'\\\\oak-smb-giocomo.stanford.edu\\groups\\giocomo\\export\\data\\Projects\\JohnKei_NPH3'\n",
    "rec_suffix = 'keicontrasttrack_ketamine1'\n",
    "for i, row in sessions.iterrows():\n",
    "    rec_base = row['Session']+'_'+rec_suffix\n",
    "    ephys_path = join(ephys_base_dir, row['Animal'], rec_base+'_g0', rec_base+'_g0_imec0')\n",
    "    lfp_file = join(ephys_path, rec_base+'_g0_tcat.imec0.lf.bin')\n",
    "    ks_file_path = ephys_path\n",
    "    print(ephys_path)\n",
    "    plot_ephys_vs_atlas(ks_file_path, ephys_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85911a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate power in each frequency band over entire session\n",
    "t = time.time()\n",
    "output_dir = r'\\\\oak-smb-giocomo.stanford.edu\\groups\\giocomo\\fkmasuda\\fkm_analysis\\EAJ_revisions\\lfp'\n",
    "ephys_base_dir = r'\\\\oak-smb-giocomo.stanford.edu\\groups\\giocomo\\export\\data\\Projects\\JohnKei_NPH3'\n",
    "rec_suffix = 'keicontrasttrack_ketamine1'\n",
    "for i, row in sessions.iterrows():\n",
    "    rec_base = row['Session']+'_'+rec_suffix\n",
    "    ephys_path = join(ephys_base_dir, row['Animal'], rec_base+'_g0', rec_base+'_g0_imec0')\n",
    "    lfp_file = join(ephys_path, rec_base+'_g0_tcat.imec0.lf.bin')\n",
    "    print(ephys_path)\n",
    "    lfp = LFP(rec_file_path=ephys_path, channels=[int(row['LFP_Channel'])], probe_type=2, n_chan=1)\n",
    "    theta_power, _ = multitaper_filtered_power(lfp.lfp, low=THETA[0], high=THETA[1], window=1)\n",
    "    theta_df = pd.DataFrame(data=theta_power)\n",
    "    theta_df.to_csv(join(output_dir, row['Session']+'_theta_power.csv'), index=False, header=False)\n",
    "    SG_power, _ = multitaper_filtered_power(lfp.lfp, low=SLOW_GAMMA[0], high=SLOW_GAMMA[1], window=1)\n",
    "    SG_df = pd.DataFrame(data=SG_power)\n",
    "    SG_df.to_csv(join(output_dir, row['Session']+'_SG_power.csv'), index=False, header=False)\n",
    "    FG_power, _ = multitaper_filtered_power(lfp.lfp, low=FAST_GAMMA[0], high=FAST_GAMMA[1], window=1)\n",
    "    FG_df = pd.DataFrame(data=FG_power)\n",
    "    FG_df.to_csv(join(output_dir, row['Session']+'_FG_power.csv'), index=False, header=False)\n",
    "    print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce80970b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\oak-smb-giocomo.stanford.edu\\groups\\giocomo\\export\\data\\Projects\\JohnKei_NPH3\\HCNe2\\HCNe2_190912_keicontrasttrack_ketamine1_g0\\HCNe2_190912_keicontrasttrack_ketamine1_g0_imec0\n"
     ]
    }
   ],
   "source": [
    "# plot and save representative PSDs over epochs\n",
    "for i, row in sessions.iloc[27:28].iterrows():\n",
    "    rec_base = row['Session']+'_'+rec_suffix\n",
    "    ephys_path = join(ephys_base_dir, row['Animal'], rec_base+'_g0', rec_base+'_g0_imec0')\n",
    "    lfp_file = join(ephys_path, rec_base+'_g0_tcat.imec0.lf.bin')\n",
    "    print(ephys_path)\n",
    "    lfp = LFP(rec_file_path=ephys_path, channels=[int(row['LFP_Channel'])], probe_type=2, n_chan=1)\n",
    "    base_lfp = deepcopy(lfp);\n",
    "    base_lfp.subset_by_time(np.array([row['Base_Start'],row['Base_End']]))\n",
    "    ctrl_lfp = deepcopy(lfp);\n",
    "    ctrl_lfp.subset_by_time(np.array([row['Ctrl_Start'],row['Ctrl_End']]))\n",
    "    ket_lfp = deepcopy(lfp);\n",
    "    ket_lfp.subset_by_time(np.array([row['Ket_Start'],row['Ket_Start']+1800]))\n",
    "    \n",
    "    freqs, psd = signal.welch(np.squeeze(base_lfp.lfp), rate)\n",
    "    plt.semilogy(freqs, psd)\n",
    "    freqs, psd = signal.welch(np.squeeze(ctrl_lfp.lfp), rate)\n",
    "    plt.semilogy(freqs, psd)\n",
    "    freqs, psd = signal.welch(np.squeeze(ket_lfp.lfp), rate)\n",
    "    plt.semilogy(freqs, psd)\n",
    "    plt.xlim([0, 100])\n",
    "    plt.ylim([0.1, 1000])\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('PSD (V**2/Hz)')\n",
    "    plt.savefig(r'\\\\oak-smb-giocomo.stanford.edu\\groups\\giocomo\\fkmasuda\\fkm_analysis\\EAJ_revisions\\27_psd.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
